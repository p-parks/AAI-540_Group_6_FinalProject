{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paula\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# READ dataset\\CEAS_08.csv and make a train and test split then save to new csv files\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('dataset/CEAS_08.csv')\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# make a new dir for autogloun to read the data\n",
    "os.makedirs('dataset_autogluon', exist_ok=True)\n",
    "\n",
    "train.to_csv('dataset_autogluon/train.csv', index=False)\n",
    "test.to_csv('dataset_autogluon/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20241003_000618\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.5\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          32\n",
      "Memory Avail:       47.80 GB / 63.75 GB (75.0%)\n",
      "Disk Space Avail:   3152.20 GB / 3725.17 GB (84.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (31323 samples, 70.25 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20241003_000618\"\n",
      "Train Data Rows:    31323\n",
      "Train Data Columns: 6\n",
      "Label Column:       label\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    49001.12 MB\n",
      "\tTrain Data (Original)  Memory Usage: 66.76 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "C:\\Users\\paula\\AppData\\Roaming\\Python\\Python311\\site-packages\\autogluon\\common\\features\\infer_types.py:118: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  result = pd.to_datetime(X, errors=\"coerce\", format=\"mixed\")\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['sender', 'subject', 'body']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 10000\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])                        : 1 | ['urls']\n",
      "\t\t('object', [])                     : 1 | ['receiver']\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['date']\n",
      "\t\t('object', ['text'])               : 3 | ['sender', 'subject', 'body']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    1 | ['receiver']\n",
      "\t\t('category', ['text_as_category'])  :    2 | ['sender', 'subject']\n",
      "\t\t('int', ['binned', 'text_special']) :   76 | ['sender.char_count', 'sender.word_count', 'sender.capital_ratio', 'sender.lower_ratio', 'sender.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    1 | ['urls']\n",
      "\t\t('int', ['datetime_as_int'])        :    5 | ['date', 'date.year', 'date.month', 'date.day', 'date.dayofweek']\n",
      "\t\t('int', ['text_ngram'])             : 6913 | ['__nlp__.00', '__nlp__.00 00', '__nlp__.000', '__nlp__.000 gorillas', '__nlp__.0000', ...]\n",
      "\t62.8s = Fit runtime\n",
      "\t6 features in original data used to generate 6998 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 416.69 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 64.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.07981355553427194, Train Rows: 28823, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.4716\t = Validation score   (accuracy)\n",
      "\t4.65s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.4712\t = Validation score   (accuracy)\n",
      "\t3.95s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.1.1`.\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.1.1`.\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9972\t = Validation score   (accuracy)\n",
      "\t7.52s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9972\t = Validation score   (accuracy)\n",
      "\t5.89s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tWarning: Exception caused CatBoost to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9972\t = Validation score   (accuracy)\n",
      "\t8.98s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9968\t = Validation score   (accuracy)\n",
      "\t7.38s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`. \n",
      "Fitting model: XGBoost ...\n",
      "\t0.9972\t = Validation score   (accuracy)\n",
      "\t12.54s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tWarning: Exception caused NeuralNetTorch to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 2.2.\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.1.1`.\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestGini': 0.5, 'XGBoost': 0.5}\n",
      "\t0.998\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 143.0s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 10961.8 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20241003_000618\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "data_root = 'dataset_autogluon/'\n",
    "train_data = TabularDataset(data_root + 'train.csv')\n",
    "test_data = TabularDataset(data_root + 'test.csv')\n",
    "\n",
    "predictor = TabularPredictor(label='label').fit(train_data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictor.predict(test_data)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9948920955178138,\n",
       " 'balanced_accuracy': 0.9950410126196556,\n",
       " 'mcc': 0.9896183049345015,\n",
       " 'roc_auc': 0.9998112745286708,\n",
       " 'f1': 0.995475113122172,\n",
       " 'precision': 0.997054158169046,\n",
       " 'recall': 0.9939010616670432}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.995020</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.794080</td>\n",
       "      <td>0.150015</td>\n",
       "      <td>12.535784</td>\n",
       "      <td>0.794080</td>\n",
       "      <td>0.150015</td>\n",
       "      <td>12.535784</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.994892</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.239892</td>\n",
       "      <td>0.228064</td>\n",
       "      <td>20.095648</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.039007</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.994254</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.443312</td>\n",
       "      <td>0.077550</td>\n",
       "      <td>7.520857</td>\n",
       "      <td>0.443312</td>\n",
       "      <td>0.077550</td>\n",
       "      <td>7.520857</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.994126</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.433464</td>\n",
       "      <td>0.067508</td>\n",
       "      <td>7.378530</td>\n",
       "      <td>0.433464</td>\n",
       "      <td>0.067508</td>\n",
       "      <td>7.378530</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.993871</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.418768</td>\n",
       "      <td>0.068009</td>\n",
       "      <td>8.983627</td>\n",
       "      <td>0.418768</td>\n",
       "      <td>0.068009</td>\n",
       "      <td>8.983627</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.993743</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.393245</td>\n",
       "      <td>0.066508</td>\n",
       "      <td>5.888525</td>\n",
       "      <td>0.393245</td>\n",
       "      <td>0.066508</td>\n",
       "      <td>5.888525</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.465969</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>5.245612</td>\n",
       "      <td>0.746475</td>\n",
       "      <td>3.946615</td>\n",
       "      <td>5.245612</td>\n",
       "      <td>0.746475</td>\n",
       "      <td>3.946615</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.465969</td>\n",
       "      <td>0.4716</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>6.086363</td>\n",
       "      <td>0.786382</td>\n",
       "      <td>4.651834</td>\n",
       "      <td>6.086363</td>\n",
       "      <td>0.786382</td>\n",
       "      <td>4.651834</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0              XGBoost    0.995020     0.9972    accuracy        0.794080   \n",
       "1  WeightedEnsemble_L2    0.994892     0.9980    accuracy        1.239892   \n",
       "2     RandomForestGini    0.994254     0.9972    accuracy        0.443312   \n",
       "3       ExtraTreesEntr    0.994126     0.9968    accuracy        0.433464   \n",
       "4       ExtraTreesGini    0.993871     0.9972    accuracy        0.418768   \n",
       "5     RandomForestEntr    0.993743     0.9972    accuracy        0.393245   \n",
       "6       KNeighborsDist    0.465969     0.4712    accuracy        5.245612   \n",
       "7       KNeighborsUnif    0.465969     0.4716    accuracy        6.086363   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.150015  12.535784                 0.794080                0.150015   \n",
       "1       0.228064  20.095648                 0.002500                0.000500   \n",
       "2       0.077550   7.520857                 0.443312                0.077550   \n",
       "3       0.067508   7.378530                 0.433464                0.067508   \n",
       "4       0.068009   8.983627                 0.418768                0.068009   \n",
       "5       0.066508   5.888525                 0.393245                0.066508   \n",
       "6       0.746475   3.946615                 5.245612                0.746475   \n",
       "7       0.786382   4.651834                 6.086363                0.786382   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0          12.535784            1       True          7  \n",
       "1           0.039007            2       True          8  \n",
       "2           7.520857            1       True          3  \n",
       "3           7.378530            1       True          6  \n",
       "4           8.983627            1       True          5  \n",
       "5           5.888525            1       True          4  \n",
       "6           3.946615            1       True          2  \n",
       "7           4.651834            1       True          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
